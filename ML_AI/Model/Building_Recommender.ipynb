{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, string, os, math, cmath, re, nltk, gensim, time, sklearn, matplotlib \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import _pickle as cPickle\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import LdaModel\n",
    "from gensim import models, corpora, similarities\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import FreqDist\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data/corpus and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load arxiv data with cleaned abstracts\n",
    "data_df = pd.read_csv(\"cleaned_data.csv\");\n",
    "data_df = data_df.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "import pickle\n",
    "\n",
    "# load corpus and dictionary \n",
    "corpus = pickle.load(open(\"corpus.pkl\",\"rb\"))\n",
    "dictionary = pickle.load(open(\"dictionary.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>authors</th>\n",
       "      <th>published</th>\n",
       "      <th>title</th>\n",
       "      <th>abstitle</th>\n",
       "      <th>prim_cat</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_count</th>\n",
       "      <th>cleaned_abstitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cs/9308101</td>\n",
       "      <td>M. L. Ginsberg</td>\n",
       "      <td>Journal of Artificial Intelligence Research, V...</td>\n",
       "      <td>dynamic backtracking</td>\n",
       "      <td>dynamic backtracking occasional need return sh...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>445</td>\n",
       "      <td>20</td>\n",
       "      <td>dynam backtrack occasion need return shallow p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>cs/9308102</td>\n",
       "      <td>M. P. Wellman</td>\n",
       "      <td>Journal of Artificial Intelligence Research, V...</td>\n",
       "      <td>a marketoriented programming environment and i...</td>\n",
       "      <td>marketoriented programming environment applica...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>798</td>\n",
       "      <td>106</td>\n",
       "      <td>marketori program environ applic distribut mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>cs/9309101</td>\n",
       "      <td>I. P. Gent, T. Walsh</td>\n",
       "      <td>Journal of Artificial Intelligence Research, V...</td>\n",
       "      <td>an empirical analysis of search in gsat</td>\n",
       "      <td>empirical analysis search gsat describe extens...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>829</td>\n",
       "      <td>39</td>\n",
       "      <td>empir analysi search gsat describ extens studi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id               authors  \\\n",
       "0  cs/9308101        M. L. Ginsberg   \n",
       "1  cs/9308102         M. P. Wellman   \n",
       "2  cs/9309101  I. P. Gent, T. Walsh   \n",
       "\n",
       "                                           published  \\\n",
       "0  Journal of Artificial Intelligence Research, V...   \n",
       "1  Journal of Artificial Intelligence Research, V...   \n",
       "2  Journal of Artificial Intelligence Research, V...   \n",
       "\n",
       "                                               title  \\\n",
       "0                               dynamic backtracking   \n",
       "1  a marketoriented programming environment and i...   \n",
       "2            an empirical analysis of search in gsat   \n",
       "\n",
       "                                            abstitle prim_cat  word_count  \\\n",
       "0  dynamic backtracking occasional need return sh...    cs.AI         445   \n",
       "1  marketoriented programming environment applica...    cs.AI         798   \n",
       "2  empirical analysis search gsat describe extens...    cs.AI         829   \n",
       "\n",
       "   title_count                                   cleaned_abstitle  \n",
       "0           20  dynam backtrack occasion need return shallow p...  \n",
       "1          106  marketori program environ applic distribut mul...  \n",
       "2           39  empir analysi search gsat describ extens studi...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(81701 unique tokens: ['approach', 'avoid', 'backtrack', 'complet', 'control']...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49207 0\n"
     ]
    }
   ],
   "source": [
    "print(len(data_df),data_df['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated entries =  0\n",
      "duplicated entries after removal =  0\n"
     ]
    }
   ],
   "source": [
    "# Dropping duplicates!\n",
    "print(\"duplicated entries = \", data_df['id'].duplicated().sum())\n",
    "data_df = data_df.drop_duplicates(subset=\"id\")\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "print(\"duplicated entries after removal = \", data_df['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.030*\"gener\" + 0.028*\"imag\" + 0.018*\"network\" + 0.013*\"use\"')\n",
      "(1, '0.014*\"social\" + 0.014*\"use\" + 0.010*\"model\" + 0.008*\"emot\"')\n",
      "(2, '0.024*\"data\" + 0.022*\"method\" + 0.021*\"learn\" + 0.017*\"featur\"')\n",
      "(3, '0.030*\"problem\" + 0.019*\"optim\" + 0.012*\"search\" + 0.012*\"cluster\"')\n",
      "(4, '0.040*\"user\" + 0.022*\"recommend\" + 0.020*\"data\" + 0.015*\"learn\"')\n",
      "(5, '0.014*\"research\" + 0.014*\"machin\" + 0.013*\"learn\" + 0.013*\"human\"')\n",
      "(6, '0.015*\"function\" + 0.015*\"gradient\" + 0.015*\"optim\" + 0.013*\"bound\"')\n",
      "(7, '0.025*\"data\" + 0.019*\"use\" + 0.018*\"predict\" + 0.017*\"detect\"')\n",
      "(8, '0.012*\"logic\" + 0.012*\"program\" + 0.011*\"use\" + 0.009*\"set\"')\n",
      "(9, '0.038*\"learn\" + 0.021*\"agent\" + 0.020*\"polici\" + 0.019*\"reinforc\"')\n",
      "(10, '0.021*\"languag\" + 0.018*\"model\" + 0.017*\"task\" + 0.012*\"text\"')\n",
      "(11, '0.030*\"learn\" + 0.024*\"train\" + 0.018*\"data\" + 0.016*\"method\"')\n",
      "(12, '0.061*\"network\" + 0.036*\"neural\" + 0.022*\"deep\" + 0.017*\"train\"')\n",
      "(13, '0.052*\"graph\" + 0.035*\"network\" + 0.035*\"adversari\" + 0.029*\"attack\"')\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "ldamodel = LdaModel.load('model14.gensim')\n",
    "\n",
    "# checking the topics\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the topic distribution of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_document_topics in module gensim.models.ldamodel:\n",
      "\n",
      "get_document_topics(bow, minimum_probability=None, minimum_phi_value=None, per_word_topics=False) method of gensim.models.ldamulticore.LdaMulticore instance\n",
      "    Get the topic distribution for the given document.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    bow : corpus : list of (int, float)\n",
      "        The document in BOW format.\n",
      "    minimum_probability : float\n",
      "        Topics with an assigned probability lower than this threshold will be discarded.\n",
      "    minimum_phi_value : float\n",
      "        If `per_word_topics` is True, this represents a lower bound on the term probabilities that are included.\n",
      "         If set to None, a value of 1e-8 is used to prevent 0s.\n",
      "    per_word_topics : bool\n",
      "        If True, this function will also return two extra lists as explained in the \"Returns\" section.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    list of (int, float)\n",
      "        Topic distribution for the whole document. Each element in the list is a pair of a topic's id, and\n",
      "        the probability that was assigned to it.\n",
      "    list of (int, list of (int, float), optional\n",
      "        Most probable topics per word. Each element in the list is a pair of a word's id, and a list of\n",
      "        topics sorted by their relevance to this word. Only returned if `per_word_topics` was set to True.\n",
      "    list of (int, list of float), optional\n",
      "        Phi relevance values, multiplied by the feature length, for each word-topic combination.\n",
      "        Each element in the list is a pair of a word's id and a list of the phi values between this word and\n",
      "        each topic. Only returned if `per_word_topics` was set to True.\n",
      "\n",
      "None\n",
      "[(3, 0.6395808), (5, 0.13037303), (9, 0.13606897), (12, 0.08021507)]\n",
      "[(3, 0.22612697), (4, 0.29882422), (7, 0.040723406), (8, 0.38624036), (9, 0.040190317)]\n",
      "[(3, 0.59826106), (5, 0.087174974), (6, 0.306777)]\n"
     ]
    }
   ],
   "source": [
    "print(help(ldamodel.get_document_topics))\n",
    "print(ldamodel.get_document_topics(corpus[0]))\n",
    "print(ldamodel.get_document_topics(corpus[1]))\n",
    "print(ldamodel.get_document_topics(corpus[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.63974237, 0.        ,\n",
       "       0.13033921, 0.        , 0.        , 0.        , 0.1358977 ,\n",
       "       0.        , 0.        , 0.08025853, 0.        ])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topic_output(model,x_bow,n_topics=14):\n",
    "    out=[0]*n_topics;\n",
    "    topics = model.get_document_topics(x_bow); \n",
    "    for x in topics: \n",
    "        out[x[0]] = x[1];\n",
    "    \n",
    "    return np.asarray(out); \n",
    "\n",
    "i=0\n",
    "topic_output(ldamodel,corpus[i],14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49207 49207 81701\n"
     ]
    }
   ],
   "source": [
    "print(len(data_df), len(corpus), len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 80397 is out of bounds for axis 1 with size 80397",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-45dac2c44288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#topic_output(ldamodel,corpus[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtemper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtopic_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-128-f408707b881b>\u001b[0m in \u001b[0;36mtopic_output\u001b[0;34m(model, x_bow, n_topics)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtopic_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_bow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mget_document_topics\u001b[0;34m(self, bow, minimum_probability, minimum_phi_value, per_word_topics)\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m         \u001b[0mtopic_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalize distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mexpElogbetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 80397 is out of bounds for axis 1 with size 80397"
     ]
    }
   ],
   "source": [
    "topic_dist = []\n",
    "for i in range(0,len(data_df)):\n",
    "    #topic_output(ldamodel,corpus[i])\n",
    "    #print(i)\n",
    "    temper = topic_output(ldamodel,corpus[i],14)\n",
    "    topic_dist.append(temper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist = np.asarray(topic_dist)\n",
    "print(topic_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "val_out = cdist(topic_dist[0].reshape(1,-1), topic_dist, 'cosine')[0]\n",
    "sorted_ind = np.argsort(val_out)\n",
    "print(sorted_ind, val_out[363])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nearest neighbors of query document. \n",
    "def cosine_neighbors(query_id,topic_dist,kneigh=10):\n",
    "    val_out = cdist(topic_dist[query_id].reshape(1,-1), \n",
    "                    topic_dist, \n",
    "                    'cosine')[0]\n",
    "    val_out = 1 + val_out\n",
    "    sorted_ind = np.argsort(val_out)\n",
    "    \n",
    "    for idx in sorted_ind[0:kneigh]:\n",
    "        print(\"document id: \",idx)\n",
    "        print(\"ArXiv id: \", data_df.iloc[idx][\"id\"])\n",
    "        print(\"Authors: \", data_df.iloc[idx][\"authors\"])\n",
    "        print(\"Title: \", data_df.iloc[idx][\"title\"])\n",
    "        print(data_df.iloc[idx][\"abstitle\"], \" \\n\")\n",
    "        print(data_df.iloc[idx][\"cleaned_abstitle\"], \" \\n\")\n",
    "        print(\"topic distribution: \\n\", topic_dist[idx])\n",
    "        print(\"================================================================== \\n\")\n",
    "\n",
    "    return sorted_ind[0:kneigh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cosine_neighbors(10010,topic_dist,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,14):\n",
    "    print(i,\" --> \", ldamodel.print_topic(i,topn=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check a famous paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[data_df[\"id\"]==\"1802.00420\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cosine_neighbors(24699,topic_dist,10); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
